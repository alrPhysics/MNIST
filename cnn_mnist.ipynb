{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1bd56089668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pixels = mnist.test.images[500].reshape((28,28))\n",
    "plt.imshow(pixels, cmap = 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[28, 28, 1]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(mnist.validation.labels))\n",
    "test = tf.reshape(mnist.train.images, [-1,28,28,1])\n",
    "test.shape.as_list()[1:]\n",
    "#mnist.train.next_batch(10)[1].shape\n",
    "#mnist.train.next_batch(10)[0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(data, filter_size, depth, stride):\n",
    "    \n",
    "    #data.shape.as_list()[3] == data.shape[3].value\n",
    "    weights = tf.Variable(tf.truncated_normal([*filter_size,data.shape.as_list()[3],depth], stddev=0.1))\n",
    "    #maybe adjust bias change from tf.zeros?\n",
    "    bias = tf.Variable(tf.zeros(depth))\n",
    "    layer = tf.nn.conv2d(data, weights, [1,stride,stride,1], padding = 'SAME')\n",
    "    layer = tf.nn.bias_add(layer, bias)\n",
    "    layer = tf.nn.relu(layer)\n",
    "    \n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten(data):\n",
    "    layer = tf.reshape(data,[-1, np.prod(data.shape.as_list()[1:])])\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fully_conn(data, num_outputs):\n",
    "    weights = tf.Variable(tf.truncated_normal([data.shape.as_list()[1], num_outputs], stddev = 0.1))\n",
    "    bias = tf.Variable(tf.zeros([num_outputs]))\n",
    "    layer = tf.add(tf.matmul(data, weights),bias)\n",
    "    layer = tf.nn.relu(layer)\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def output(data, num_outputs):\n",
    "    weights = tf.Variable(tf.truncated_normal([data.shape.as_list()[1], num_outputs], stddev=0.1))\n",
    "    bias = tf.Variable(tf.zeros([num_outputs]))\n",
    "    out = tf.add(tf.matmul(data, weights),bias)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_net(data):\n",
    "    #conv_layer(data, filter_size, depth, stride)\n",
    "        \n",
    "    conv1 = conv_layer(data,(5,5),4,1)\n",
    "    conv2 = conv_layer(conv1, (4,4),8,2)\n",
    "    conv3 = conv_layer(conv2, (4,4),12,2)\n",
    "    flat = flatten(conv3)\n",
    "    fc = fully_conn(flat, 200)\n",
    "    out = output(fc, 10)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODIFY\n",
    "tf.reset_default_graph()\n",
    "\n",
    "#x = tf.placeholder(tf.float32, [None, 28, 28, 1],'x')\n",
    "#y = tf.placeholder(tf.float32, [None,10],'y')\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "x_shaped = tf.reshape(x, [-1,28,28,1])\n",
    "y = tf.placeholder(tf.float32, [None,10])\n",
    "\n",
    "\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x_shaped)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2750\n",
      "Epoch  1, MNIST final batch: Loss: 0.04807165637612343  Test Accuracy: 0.9634000658988953\n",
      "Epoch  2, MNIST final batch: Loss: 0.13587458431720734  Test Accuracy: 0.9707001447677612\n",
      "Epoch  3, MNIST final batch: Loss: 0.012726414017379284  Test Accuracy: 0.9792001247406006\n",
      "Epoch  4, MNIST final batch: Loss: 0.07085911929607391  Test Accuracy: 0.9824001789093018\n",
      "Epoch  5, MNIST final batch: Loss: 0.02223198674619198  Test Accuracy: 0.9803001284599304\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    batches = int(len(mnist.train.labels)/batch_size)\n",
    "    print(batches)\n",
    "    for epoch in range(epochs):\n",
    "        for batch_i in range(1000):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            sess.run(optimizer, feed_dict={x:batch_x, y: batch_y})\n",
    "            #print(batch_i)\n",
    "            loss = sess.run(cost, feed_dict = {x:batch_x, y: batch_y})\n",
    "            test_acc = sess.run(accuracy, feed_dict = {x:mnist.test.images, y:mnist.test.labels})   \n",
    "        print('Epoch {:>2}, MNIST final batch: '.format(epoch+1), end='')\n",
    "        print('Loss: {}  Test Accuracy: {}'.format(loss, test_acc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
